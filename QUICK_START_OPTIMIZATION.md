# Quick Start: PRD Optimization Feature

## What We Built

A complete LLM-powered workflow that:
- âœ… Analyzes PRD facts using OpenRouter API (Claude 3.5 Sonnet)
- âœ… Reviews fact quality and suggests improvements
- âœ… Restructures knowledge graph for optimal code generation
- âœ… Optimizes requirements for "vibe coding"

## Files Created/Modified

### Backend
- âœ… `backend/.env` - Added OpenRouter API key
- âœ… `backend/app/core/config.py` - Added OpenRouter configuration
- âœ… `backend/app/services/openrouter_service.py` - **NEW** - OpenRouter LLM integration
- âœ… `backend/app/services/prd_optimizer_service.py` - **NEW** - PRD optimization orchestrator
- âœ… `backend/app/api/routes.py` - Added `/prds/{prd_id}/optimize` endpoint

### Frontend
- âœ… `frontend/src/types/index.ts` - Added OptimizeResponse type
- âœ… `frontend/src/services/api.ts` - Added optimizePRD function
- âœ… `frontend/src/components/PRDList.tsx` - Added "Optimize for Vibe Coding" button

### Testing & Documentation
- âœ… `test_prd_optimizer.py` - **NEW** - End-to-end test script
- âœ… `PRD_OPTIMIZATION_GUIDE.md` - **NEW** - Comprehensive feature documentation
- âœ… `QUICK_START_OPTIMIZATION.md` - **NEW** - This quick start guide

## How to Use

### Option 1: Via Frontend (Recommended)

1. **Start the infrastructure**:
   ```bash
   cd /home/jwscho/cvPRD/infrastructure/docker
   docker-compose up -d
   ```

2. **Start the backend**:
   ```bash
   cd /home/jwscho/cvPRD/backend
   uvicorn app.main:app --reload
   ```

3. **Start the frontend**:
   ```bash
   cd /home/jwscho/cvPRD/frontend
   npm run dev
   ```

4. **Use the feature**:
   - Open http://localhost:3000 in your browser
   - Create a PRD or select an existing one
   - Click "ðŸš€ Optimize for Vibe Coding"
   - Wait 30-60 seconds for LLM analysis
   - Review the optimization results

### Option 2: Via API (cURL)

```bash
# First, create a PRD (or use existing PRD ID)
curl -X POST http://localhost:8000/api/v1/prds \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Test PRD",
    "description": "A test PRD for optimization",
    "sections": [
      {
        "title": "Features",
        "content": "User login. Product catalog. Shopping cart.",
        "priority": "high",
        "tags": ["core"]
      }
    ]
  }'

# Copy the prd_id from response, then optimize
curl -X POST "http://localhost:8000/api/v1/prds/{PRD_ID}/optimize?optimization_goal=vibe%20coding"
```

### Option 3: Via Test Script (Easiest)

```bash
cd /home/jwscho/cvPRD
python3 test_prd_optimizer.py
```

This will:
1. Create a sample e-commerce PRD
2. Run optimization
3. Display detailed results
4. Save results to JSON file

## What Happens During Optimization

```
Your PRD Facts
     â†“
[1] Fetch all facts from Vector DB & Knowledge Graph
     â†“
[2] Send to OpenRouter (Claude 3.5 Sonnet)
     â”‚
     â”œâ”€ Analyze fact quality (clarity, completeness, specificity)
     â”œâ”€ Suggest optimized text for each fact
     â”œâ”€ Recommend new facts to add
     â””â”€ Identify missing relationships
     â†“
[3] Apply LLM recommendations
     â”‚
     â”œâ”€ Update existing facts with optimized text
     â”œâ”€ Create new facts suggested by LLM
     â””â”€ Add new relationships between facts
     â†“
[4] Update databases
     â”‚
     â”œâ”€ Re-embed optimized facts (new vectors)
     â”œâ”€ Update Qdrant vector database
     â””â”€ Update Neo4j knowledge graph
     â†“
Optimized PRD Ready for Code Generation!
```

## Example Results

After optimization, you'll see:

```
âœ“ PRD "E-Commerce Platform" optimized successfully!

Updated: 5 facts
Created: 3 new facts
New relationships: 7

Assessment: The PRD now includes explicit authentication
mechanisms, detailed data models, and clear API contracts.
All requirements are specific and actionable for code generation.
```

## Configuration

The OpenRouter API key is already configured in `/home/jwscho/cvPRD/backend/.env`:

```bash
OPENROUTER_API_KEY=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
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
```

### Changing the LLM Model

Edit `.env` to use a different model:

```bash
# Faster, cheaper (good for testing)
OPENROUTER_MODEL=anthropic/claude-3-haiku

# Most capable (best quality, slower)
OPENROUTER_MODEL=anthropic/claude-3-opus

# OpenAI alternative
OPENROUTER_MODEL=openai/gpt-4-turbo
```

## Verification Steps

### 1. Check Backend is Running
```bash
curl http://localhost:8000/api/v1/health
```
Should return: `{"status":"healthy",...}`

### 2. Check OpenRouter Configuration
```bash
cd /home/jwscho/cvPRD/backend
grep OPENROUTER .env
```
Should show your API key

### 3. Test the Optimizer
```bash
python3 test_prd_optimizer.py
```
Should create a PRD and optimize it successfully

## Troubleshooting

### Backend won't start
```bash
# Check if ports are in use
lsof -i :8000

# Install dependencies
cd /home/jwscho/cvPRD/backend
pip install -r requirements.txt
```

### "OpenRouter API key not configured"
```bash
# Verify .env file exists
ls -la /home/jwscho/cvPRD/backend/.env

# Check content
cat /home/jwscho/cvPRD/backend/.env | grep OPENROUTER
```

### Services not running
```bash
# Check Docker services
cd /home/jwscho/cvPRD/infrastructure/docker
docker-compose ps

# Start if needed
docker-compose up -d
```

## Next Steps

1. **Test with your own PRDs**:
   - Create a real PRD with your actual requirements
   - Run optimization
   - Review the LLM suggestions
   - Use optimized PRD for code generation

2. **Integrate with code generation**:
   - Use optimized facts as input to code generation LLMs
   - Compare code quality before/after optimization
   - Iterate on optimization prompts

3. **Customize optimization goals**:
   - Try different optimization goals
   - Modify the prompt in `openrouter_service.py`
   - Experiment with different LLM models

## Performance Expectations

- **Small PRD** (5-10 facts): ~15-30 seconds
- **Medium PRD** (20-30 facts): ~30-60 seconds
- **Large PRD** (50+ facts): ~60-120 seconds

Times vary based on:
- LLM model selected (Haiku faster, Opus slower)
- OpenRouter API response time
- Number of facts in PRD
- Complexity of optimizations needed

## Cost Estimates

Using Claude 3.5 Sonnet via OpenRouter:
- **Small PRD**: ~$0.05-0.10 per optimization
- **Medium PRD**: ~$0.10-0.25 per optimization
- **Large PRD**: ~$0.25-0.50 per optimization

Note: Costs are estimates and depend on token usage. Check OpenRouter pricing for latest rates.

## Getting Help

- **Feature Documentation**: See `PRD_OPTIMIZATION_GUIDE.md`
- **Backend Logs**: `tail -f /home/jwscho/cvPRD/backend/logs/app.log`
- **Test Script**: Run `python3 test_prd_optimizer.py` for diagnostics

## What Makes This Special?

ðŸŽ¯ **Optimized for "Vibe Coding"**
- Facts are reformulated for maximum code generation quality
- LLM adds missing technical details developers need
- Relationships ensure consistent implementation

ðŸ§  **AI-Powered Analysis**
- Claude 3.5 Sonnet evaluates every fact
- Identifies ambiguities and gaps
- Suggests concrete improvements

ðŸ”„ **Automatic Knowledge Graph Restructuring**
- Updates vector embeddings for better search
- Adds missing relationships between facts
- Creates new facts to fill gaps

ðŸ“Š **Transparent Results**
- See exactly what changed
- Review LLM reasoning
- Full analysis saved to JSON

---

**Ready to optimize your PRDs for better code generation?**

Start with: `python3 test_prd_optimizer.py`
